{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13de2198-06f3-4947-95a2-3618d25a1ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913efb14-1f1a-40bf-8fe2-cf938a67b330",
   "metadata": {},
   "source": [
    "**Import Question Bank**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca525378-f44f-4ecb-b6a4-3999141c6581",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"da_questions.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    QA_KB = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0ee0110-a30f-4c0c-b856-7b69e81bdfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [(item[\"q\"] + \" \" + item[\"a\"]) for item in QA_KB]\n",
    "questions = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e311d6af-45a9-448d-afee-b31fc57202c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the difference between a data analyst and a data scientist? A data analyst focuses on querying, cleaning, and visualizing data to generate insights, while a data scientist builds predictive models and uses machine learning to forecast outcomes.',\n",
       " 'What is SQL used for in data analytics? SQL is used to query, filter, aggregate, join, and manipulate structured data stored in relational databases.',\n",
       " 'What are the different types of joins in SQL? The main SQL joins are INNER JOIN, LEFT JOIN, RIGHT JOIN, FULL JOIN, and CROSS JOIN.',\n",
       " 'What is normalization in databases? Normalization is the process of organizing data to reduce redundancy and improve data integrity.',\n",
       " 'What is ETL? ETL stands for Extract, Transform, Load. It is the process of extracting data from sources, transforming it into usable format, and loading it into a data warehouse.',\n",
       " 'What is the difference between WHERE and HAVING in SQL? WHERE filters rows before aggregation, while HAVING filters results after aggregation.',\n",
       " 'What is overfitting in machine learning? Overfitting occurs when a model learns noise and patterns specific to the training data, reducing its ability to generalize to new data.',\n",
       " 'What is underfitting? Underfitting occurs when a model is too simple and fails to capture the underlying patterns in the data.',\n",
       " 'What is cross-validation? Cross-validation is a technique used to evaluate model performance by splitting the dataset into multiple training and testing folds.',\n",
       " 'What is the bias-variance tradeoff? The bias-variance tradeoff describes the balance between a model that is too simple (high bias) and one that is too complex (high variance).',\n",
       " 'What evaluation metrics are used for classification? Common classification metrics include accuracy, precision, recall, F1-score, ROC-AUC, and confusion matrix.',\n",
       " 'What evaluation metrics are used for regression? Common regression metrics include Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and R-squared.',\n",
       " 'What is logistic regression? Logistic regression is a classification algorithm used to predict binary outcomes using a logistic function.',\n",
       " 'What is linear regression? Linear regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables.',\n",
       " 'What is feature engineering? Feature engineering is the process of creating or transforming variables to improve model performance.',\n",
       " 'What is feature selection? Feature selection is the process of choosing the most relevant variables for building a predictive model.',\n",
       " 'What is data cleaning? Data cleaning involves handling missing values, removing duplicates, correcting errors, and standardizing formats.',\n",
       " 'What is exploratory data analysis (EDA)? EDA is the process of analyzing datasets to summarize their main characteristics using visualizations and statistical methods.',\n",
       " 'What is a confusion matrix? A confusion matrix is a table used to evaluate classification models by comparing predicted and actual values.',\n",
       " 'What is A/B testing? A/B testing is an experiment comparing two versions of a product or feature to determine which performs better.',\n",
       " 'What is hypothesis testing? Hypothesis testing is a statistical method used to determine whether there is enough evidence to reject a null hypothesis.',\n",
       " 'What is a p-value? A p-value measures the probability of observing results at least as extreme as the current data under the null hypothesis.',\n",
       " 'What is a data warehouse? A data warehouse is a centralized repository used to store structured data for reporting and analysis.',\n",
       " 'What is a data lake? A data lake stores raw, structured, and unstructured data in its native format for future analysis.',\n",
       " 'What is the difference between supervised and unsupervised learning? Supervised learning uses labeled data, while unsupervised learning finds patterns in unlabeled data.',\n",
       " 'What is clustering? Clustering is an unsupervised learning technique used to group similar data points together.',\n",
       " 'What is K-means? K-means is a clustering algorithm that partitions data into K distinct groups based on distance from centroids.',\n",
       " 'What is dimensionality reduction? Dimensionality reduction reduces the number of features in a dataset while preserving important information.',\n",
       " 'What is PCA? Principal Component Analysis (PCA) is a dimensionality reduction technique that transforms correlated variables into uncorrelated principal components.',\n",
       " 'What is time series forecasting? Time series forecasting predicts future values based on historical time-dependent data.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58f656a-7e2c-45a1-a80a-376107d1b55e",
   "metadata": {},
   "source": [
    "**Clean text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f20caf93-42ca-4e87-9dca-eb193b2404da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37779a09-3bcf-41d3-94e2-032038981f7e",
   "metadata": {},
   "source": [
    "**TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c81bb2dd-1d5f-4e5f-aad9-7dcff1199b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is the difference between a data analyst ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is sql used for in data analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what are the different types of joins in sql</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is normalization in databases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is etl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions\n",
       "0  what is the difference between a data analyst ...\n",
       "1             what is sql used for in data analytics\n",
       "2       what are the different types of joins in sql\n",
       "3                 what is normalization in databases\n",
       "4                                        what is etl"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = [clean_text(item[\"q\"]) for item in QA_KB]\n",
    "df = pd.DataFrame(q,columns=[\"questions\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "237302b0-770c-4c46-9f30-a6fa973df312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>TFIDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is the difference between a data analyst ...</td>\n",
       "      <td>{'analyst': 0.475, 'data': 0.632, 'difference'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is sql used for in data analytics</td>\n",
       "      <td>{'analytics': 0.601, 'data': 0.4, 'sql': 0.49,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what are the different types of joins in sql</td>\n",
       "      <td>{'different': 0.522, 'joins': 0.522, 'sql': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is normalization in databases</td>\n",
       "      <td>{'databases': 0.707, 'normalization': 0.707}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is etl</td>\n",
       "      <td>{'etl': 1.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions  \\\n",
       "0  what is the difference between a data analyst ...   \n",
       "1             what is sql used for in data analytics   \n",
       "2       what are the different types of joins in sql   \n",
       "3                 what is normalization in databases   \n",
       "4                                        what is etl   \n",
       "\n",
       "                                               TFIDF  \n",
       "0  {'analyst': 0.475, 'data': 0.632, 'difference'...  \n",
       "1  {'analytics': 0.601, 'data': 0.4, 'sql': 0.49,...  \n",
       "2  {'different': 0.522, 'joins': 0.522, 'sql': 0....  \n",
       "3       {'databases': 0.707, 'normalization': 0.707}  \n",
       "4                                       {'etl': 1.0}  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "X = vectorizer.fit_transform(df[\"questions\"])\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "results = []\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    row = X[i].toarray().flatten()\n",
    "    word_scores = {\n",
    "        feature_names[j]: round(row[j], 3)\n",
    "        for j in range(len(row)) if row[j] > 0\n",
    "    }\n",
    "    results.append(word_scores)\n",
    "\n",
    "df[\"TFIDF\"] = results\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adb68f91-9b99-4c36-b8a8-d7ca731c4bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer = TfidfVectorizer(stop_words=\"english\",norm=None)\n",
    "#X = vectorizer.fit_transform(df[\"questions\"])\n",
    "def dotproduct(query):\n",
    "    query_vec = vectorizer.transform([query])\n",
    "    query_array = query_vec.toarray()[0]\n",
    "\n",
    "    dot_products = np.dot(X, query_vec.T).toarray().flatten()\n",
    "    doc_magnitudes = np.linalg.norm(X.toarray(), axis=1)\n",
    "    query_magnitude = np.linalg.norm(query_vec.toarray())\n",
    "    cosine_scores = dot_products / (doc_magnitudes * query_magnitude + 1e-10)\n",
    "    out = pd.DataFrame({\n",
    "        \"Query\": query,\n",
    "        \"questions\": df[\"questions\"].values,\n",
    "        \"Dot_Product\": dot_products,\n",
    "        \"Doc Magnitude\": doc_magnitudes,\n",
    "        \"Query_Magnitude\": np.full(len(df), query_magnitude),\n",
    "        \"Cosine_Similarity\": cosine_scores\n",
    "    })\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd725105-4ea5-4679-b0a4-551e76baa99a",
   "metadata": {},
   "source": [
    "**Vectorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0bc5c31-0be0-4696-abea-471594dfe08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(preprocessor=clean_text, ngram_range=(1,2))\n",
    "question_vectors = vectorizer.fit_transform(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e734a6e-1dbb-4c9f-820e-3145308ada8d",
   "metadata": {},
   "source": [
    "**Retrieval Funciton**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45ad707c-4a1c-4229-bd2f-8185fd9c3415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(user_query, threshold=0.05):\n",
    "    query_vec = vectorizer.transform([user_query])\n",
    "    similarities = cosine_similarity(query_vec, question_vectors).flatten()\n",
    "\n",
    "    best_index = similarities.argmax()\n",
    "    best_score = similarities[best_index]\n",
    "\n",
    "    if best_score < threshold:\n",
    "        return \"I don't have an answer for that yet. Try asking again\"\n",
    "\n",
    "    return QA_KB[best_index][\"a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f68c2693-f29b-4acc-ac74-eb4bb17f05bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat():\n",
    "    print(\" Interview FAQ Chatbot (type 'quit' to exit)\")\n",
    "    while True:\n",
    "        user_input = input(\"\\nYou: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\"]:\n",
    "            print(\"Bot: Goodbye!\")\n",
    "            break\n",
    "        response = get_answer(user_input)\n",
    "        print(\"Bot:\", response)\n",
    "        dotproduct(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2058d5-2ddb-4d87-8cb0-c29da3db4625",
   "metadata": {},
   "source": [
    "**Chat Box**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae4be072-859f-40c1-8d63-4628fe8566a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Interview FAQ Chatbot (type 'quit' to exit)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  sql\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: SQL is used to query, filter, aggregate, join, and manipulate structured data stored in relational databases.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: dimension mismatch with signature (n,k=53),(k=761,m)->(n,m)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 10\u001b[0m, in \u001b[0;36mchat\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m response \u001b[38;5;241m=\u001b[39m get_answer(user_input)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBot:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mdotproduct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m, in \u001b[0;36mdotproduct\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m      4\u001b[0m query_vec \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mtransform([query])\n\u001b[0;32m      5\u001b[0m query_array \u001b[38;5;241m=\u001b[39m query_vec\u001b[38;5;241m.\u001b[39mtoarray()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 7\u001b[0m dot_products \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_vec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtoarray()\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m      8\u001b[0m doc_magnitudes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(X\u001b[38;5;241m.\u001b[39mtoarray(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      9\u001b[0m query_magnitude \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(query_vec\u001b[38;5;241m.\u001b[39mtoarray())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\project\\lib\\site-packages\\scipy\\sparse\\_matrix.py:45\u001b[0m, in \u001b[0;36mspmatrix.__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__mul__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_matmul_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\project\\lib\\site-packages\\scipy\\sparse\\_base.py:633\u001b[0m, in \u001b[0;36m_spbase._matmul_dispatch\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(other):\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m N \u001b[38;5;241m!=\u001b[39m other\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 633\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    634\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (n,k=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m),(k=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mother\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,m)->(n,m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    635\u001b[0m         )\n\u001b[0;32m    636\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_matmul_sparse(other)\n\u001b[0;32m    638\u001b[0m \u001b[38;5;66;03m# If it's a list or whatever, treat it like an array\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: dimension mismatch with signature (n,k=53),(k=761,m)->(n,m)"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e2e8c8-ad47-4985-abaf-13c96a8bbd11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (project)",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
